{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e620405-1636-4f5e-9595-5e69cb082b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\india\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn matplotlib seaborn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817d7fce-ee77-4844-b1a3-6dec413e289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump to back Palestinian 'self-determination'...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 12, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desperate travelers crowd Puerto Rico airport ...</td>\n",
       "      <td>SAN JUAN, Puerto Rico (Reuters) - Hundreds of ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Five Cops Handcuff Dr. Dre At His Home Becaus...</td>\n",
       "      <td>If Dr. Dre were a white guy the police would h...</td>\n",
       "      <td>News</td>\n",
       "      <td>July 26, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Russian soldiers killed by shelling in Syr...</td>\n",
       "      <td>MOSCOW (Reuters) - Two Russian servicemen have...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDERCOVER NYPD COP Busts 2 Women Building Bom...</td>\n",
       "      <td>Thank goodness these Muslim women have a frien...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Nov 1, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump to back Palestinian 'self-determination'...   \n",
       "1  Desperate travelers crowd Puerto Rico airport ...   \n",
       "2   Five Cops Handcuff Dr. Dre At His Home Becaus...   \n",
       "3  Two Russian soldiers killed by shelling in Syr...   \n",
       "4  UNDERCOVER NYPD COP Busts 2 Women Building Bom...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - President Donald Trump ...  politicsNews   \n",
       "1  SAN JUAN, Puerto Rico (Reuters) - Hundreds of ...     worldnews   \n",
       "2  If Dr. Dre were a white guy the police would h...          News   \n",
       "3  MOSCOW (Reuters) - Two Russian servicemen have...     worldnews   \n",
       "4  Thank goodness these Muslim women have a frien...      politics   \n",
       "\n",
       "                  date  label  \n",
       "0        May 12, 2017       1  \n",
       "1  September 25, 2017       1  \n",
       "2        July 26, 2016      0  \n",
       "3   September 4, 2017       1  \n",
       "4          Nov 1, 2015      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df_fake = pd.read_csv(r'C:\\Users\\india\\Documents\\fake_news_detection\\Fake.csv')\n",
    "df_real = pd.read_csv(r'C:\\Users\\india\\Documents\\fake_news_detection\\True.csv')\n",
    "\n",
    "# Add labels\n",
    "df_fake['label'] = 0  # Fake\n",
    "df_real['label'] = 1  # Real\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # Shuffle the data\n",
    "\n",
    "# Check structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89a66f1-51b8-4bf8-a133-bc5ea4f40aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\india\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>washington reuter presid donald trump express ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAN JUAN, Puerto Rico (Reuters) - Hundreds of ...</td>\n",
       "      <td>san juan puerto rico reuter hundr strand touri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Dr. Dre were a white guy the police would h...</td>\n",
       "      <td>dr dre white guy polic would treat total diffe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  WASHINGTON (Reuters) - President Donald Trump ...   \n",
       "1  SAN JUAN, Puerto Rico (Reuters) - Hundreds of ...   \n",
       "2  If Dr. Dre were a white guy the police would h...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  washington reuter presid donald trump express ...  \n",
       "1  san juan puerto rico reuter hundr strand touri...  \n",
       "2  dr dre white guy polic would treat total diffe...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "df[['text', 'clean_text']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21ad97e-d0fc-4715-834f-d3be64fc11b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 35918\n",
      "Test set size: 8980\n",
      "Sample training data:\n",
      " 36335                                                     \n",
      "12384    windhoek reuter namibia govern tuesday reject ...\n",
      "24419    philadelphia reuter democrat convent unfold on...\n",
      "24740    washington reuter obama administr thursday unv...\n",
      "27039    presid trump prove run white hous vastli diffe...\n",
      "Name: clean_text, dtype: object\n",
      "Sample training labels:\n",
      " 36335    0\n",
      "12384    1\n",
      "24419    1\n",
      "24740    1\n",
      "27039    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = cleaned news text\n",
    "X = df['clean_text']\n",
    "\n",
    "# y = label (0 for fake, 1 for real)\n",
    "y = df['label']\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Sample training data:\\n\", X_train.head())\n",
    "print(\"Sample training labels:\\n\", y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df57d3d4-058c-447b-a683-9f7330b44b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (35918, 5000)\n",
      "TF-IDF test shape: (8980, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TF-IDF vectorizer with max 5000 words\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit on training data and transform both train & test\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(\"TF-IDF train shape:\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4106989-a6e5-4b6c-be62-d03a5d8df463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891982182628062\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4685\n",
      "           1       0.99      0.99      0.99      4295\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd6d736-4d86-4b01-9241-881616540a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'fake_news_model.pkl')\n",
    "\n",
    "# Save TF-IDF vectorizer\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19447de1-3274-47c2-b0c6-b6be183669b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake\n"
     ]
    }
   ],
   "source": [
    "# Load model and vectorizer\n",
    "loaded_model = joblib.load('fake_news_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Example input\n",
    "news_text = \"Government announces new plans for education reform\"\n",
    "\n",
    "# Preprocess and predict\n",
    "cleaned = clean_text(news_text)  # use your clean_text() function\n",
    "vector = loaded_vectorizer.transform([cleaned])\n",
    "prediction = loaded_model.predict(vector)\n",
    "\n",
    "print(\"Prediction:\", \"Real\" if prediction[0] == 1 else \"Fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b558e77-de60-4544-b087-132094706caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
